output_dir: "output/image_lora"
pretrained_model_path: "./stable-diffusion-v1-5"
unet_subfolder: "unet_webvidlora_v3"

train_data:
  num_frames: 1
  sample_stride: 5
  is_image: true

validation_data:
  prompts:
    - "a person holding plate with a fork on it,a person holding plate with a fork on it,take plate"
    - "a person cleaning a kitchen sink with a sponge,a person cleaning a kitchen sink with a sponge,throw cloth"
    - "a person holding a frying pan in front of a microwave,a person holding a frying panin front of a microwave,move lid"
    - "a person puting down plate into the sink,a person puting down plate into the sink,empty mug into sink"
    - "a person washing their hands in a sink,a person washing their hands in a sink,damp sponge"
    - "a person pouring something into a bowl in a kitchen,a person pouring something into a bowl in a kitchen,put tea into cupboard"
    - "a person stirring something in a pot on a stove,a person stirring something in a pot on a stove,pour lemon curd mixture"
    - "a person cutting a piece of food on a kitchen counter,a person cutting a piece of food on a kitchen counter,cut food"
  num_inference_steps: 50
  guidance_scale: 8.

noise_scheduler_kwargs:
  num_train_timesteps: 1000
  beta_start: 0.00085
  beta_end: 0.012
  beta_schedule: "scaled_linear"
  steps_offset: 1
  clip_sample: false

do_sanity_check:      true
max_train_epoch:      -1
max_train_steps:      20000
validation_steps:       2000
validation_steps_tuple: [2,]

learning_rate:    1.e-4

lora_rank: 2

num_workers: 8
train_batch_size: 4
gradient_accumulation_steps: 16

checkpointing_epochs: -1
checkpointing_steps:  5000

mixed_precision_training: true
enable_xformers_memory_efficient_attention: false

global_seed: 42
logger_interval: 10
